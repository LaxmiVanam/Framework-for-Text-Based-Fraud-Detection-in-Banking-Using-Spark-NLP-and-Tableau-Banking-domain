from sparknlp.base import DocumentAssembler, Pipeline
from sparknlp.annotator import Tokenizer, NerDLModel, SentenceDetector, SentimentDLModel
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize Spark on AWS EMR
spark = SparkSession.builder \
    .appName("FraudDetectionNLP") \
    .config("spark.jars.packages", "com.johnsnowlabs.nlp:spark-nlp_2.12:5.5.0") \
    .getOrCreate()

# Define pipeline
document = DocumentAssembler().setInputCol("text").setOutputCol("document")
sentence = SentenceDetector().setInputCols(["document"]).setOutputCol("sentence")
tokenizer = Tokenizer().setInputCols(["sentence"]).setOutputCol("token")
ner = NerDLModel.pretrained("onto_100", "en") \
    .setInputCols(["sentence", "token"]).setOutputCol("entities")
sentiment = SentimentDLModel.pretrained("sentimentdl_use_twitter", "en") \
    .setInputCols(["sentence", "token"]).setOutputCol("sentiment")

pipeline = Pipeline(stages=[document, sentence, tokenizer, ner, sentiment])

# Load example data from S3
data = spark.read.text("s3://bank-data/raw_text/")

# Process text
model = pipeline.fit(data)
result = model.transform(data)

# Structure outputs
output = result.select(
    col("text").alias("original_text"),
    col("entities.result").alias("entities"),
    col("sentiment.result").alias("sentiment")
)

# Save as Parquet
output.write.mode("overwrite").parquet("s3://bank-data/nlp_outputs/")
